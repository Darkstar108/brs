import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

_weights_dict = dict()

def load_weights(weight_file):
    if weight_file == None:
        return

    try:
        weights_dict = np.load(weight_file, allow_pickle=True).item()
    except:
        weights_dict = np.load(weight_file, allow_pickle=True, encoding='bytes').item()

    return weights_dict

class KitModel(nn.Module):

    
    def __init__(self, weight_file):
        super(KitModel, self).__init__()
        global _weights_dict
        _weights_dict = load_weights(weight_file)

        self.conv1 = self.__conv(2, name='conv1', in_channels=5, out_channels=64, kernel_size=(7, 7), stride=(2, 2), groups=1, bias=False)
        self.conv1_bn = self.__batch_normalization(2, 'conv1/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_1_x1_bn = self.__batch_normalization(2, 'conv2_1/x1/bn', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_1_x1 = self.__conv(2, name='conv2_1/x1', in_channels=64, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_1_x2_bn = self.__batch_normalization(2, 'conv2_1/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_1_x2 = self.__conv(2, name='conv2_1/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_2_x1_bn = self.__batch_normalization(2, 'conv2_2/x1/bn', num_features=96, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_2_x1 = self.__conv(2, name='conv2_2/x1', in_channels=96, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_2_x2_bn = self.__batch_normalization(2, 'conv2_2/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_2_x2 = self.__conv(2, name='conv2_2/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_3_x1_bn = self.__batch_normalization(2, 'conv2_3/x1/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_3_x1 = self.__conv(2, name='conv2_3/x1', in_channels=128, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_3_x2_bn = self.__batch_normalization(2, 'conv2_3/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_3_x2 = self.__conv(2, name='conv2_3/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_4_x1_bn = self.__batch_normalization(2, 'conv2_4/x1/bn', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_4_x1 = self.__conv(2, name='conv2_4/x1', in_channels=160, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_4_x2_bn = self.__batch_normalization(2, 'conv2_4/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_4_x2 = self.__conv(2, name='conv2_4/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_5_x1_bn = self.__batch_normalization(2, 'conv2_5/x1/bn', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_5_x1 = self.__conv(2, name='conv2_5/x1', in_channels=192, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_5_x2_bn = self.__batch_normalization(2, 'conv2_5/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_5_x2 = self.__conv(2, name='conv2_5/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_6_x1_bn = self.__batch_normalization(2, 'conv2_6/x1/bn', num_features=224, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_6_x1 = self.__conv(2, name='conv2_6/x1', in_channels=224, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2_6_x2_bn = self.__batch_normalization(2, 'conv2_6/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv2_6_x2 = self.__conv(2, name='conv2_6/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2_blk_bn = self.__batch_normalization(2, 'conv2_blk/bn', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_4_1 = self.__conv(2, name='conv_SE_1/4_1', in_channels=256, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv2_blk = self.__conv(2, name='conv2_blk', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv_SE_1_4_2 = self.__conv(2, name='conv_SE_1/4_2', in_channels=16, out_channels=256, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv3_1_x1_bn = self.__batch_normalization(2, 'conv3_1/x1/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_1_x1 = self.__conv(2, name='conv3_1/x1', in_channels=128, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_1_x2_bn = self.__batch_normalization(2, 'conv3_1/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_4 = self.__conv(2, name='conv_SE_1/4', in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv3_1_x2 = self.__conv(2, name='conv3_1/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_SE_1_4 = self.__batch_normalization(2, 'bn_SE_1/4', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_2_x1_bn = self.__batch_normalization(2, 'conv3_2/x1/bn', num_features=160, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_2_x1 = self.__conv(2, name='conv3_2/x1', in_channels=160, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_2_x2_bn = self.__batch_normalization(2, 'conv3_2/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_2_x2 = self.__conv(2, name='conv3_2/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_3_x1_bn = self.__batch_normalization(2, 'conv3_3/x1/bn', num_features=192, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_3_x1 = self.__conv(2, name='conv3_3/x1', in_channels=192, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_3_x2_bn = self.__batch_normalization(2, 'conv3_3/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_3_x2 = self.__conv(2, name='conv3_3/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_4_x1_bn = self.__batch_normalization(2, 'conv3_4/x1/bn', num_features=224, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_4_x1 = self.__conv(2, name='conv3_4/x1', in_channels=224, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_4_x2_bn = self.__batch_normalization(2, 'conv3_4/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_4_x2 = self.__conv(2, name='conv3_4/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_5_x1_bn = self.__batch_normalization(2, 'conv3_5/x1/bn', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_5_x1 = self.__conv(2, name='conv3_5/x1', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_5_x2_bn = self.__batch_normalization(2, 'conv3_5/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_5_x2 = self.__conv(2, name='conv3_5/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_6_x1_bn = self.__batch_normalization(2, 'conv3_6/x1/bn', num_features=288, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_6_x1 = self.__conv(2, name='conv3_6/x1', in_channels=288, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_6_x2_bn = self.__batch_normalization(2, 'conv3_6/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_6_x2 = self.__conv(2, name='conv3_6/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_7_x1_bn = self.__batch_normalization(2, 'conv3_7/x1/bn', num_features=320, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_7_x1 = self.__conv(2, name='conv3_7/x1', in_channels=320, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_7_x2_bn = self.__batch_normalization(2, 'conv3_7/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_7_x2 = self.__conv(2, name='conv3_7/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_8_x1_bn = self.__batch_normalization(2, 'conv3_8/x1/bn', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_8_x1 = self.__conv(2, name='conv3_8/x1', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_8_x2_bn = self.__batch_normalization(2, 'conv3_8/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_8_x2 = self.__conv(2, name='conv3_8/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_9_x1_bn = self.__batch_normalization(2, 'conv3_9/x1/bn', num_features=384, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_9_x1 = self.__conv(2, name='conv3_9/x1', in_channels=384, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_9_x2_bn = self.__batch_normalization(2, 'conv3_9/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_9_x2 = self.__conv(2, name='conv3_9/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_10_x1_bn = self.__batch_normalization(2, 'conv3_10/x1/bn', num_features=416, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_10_x1 = self.__conv(2, name='conv3_10/x1', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_10_x2_bn = self.__batch_normalization(2, 'conv3_10/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_10_x2 = self.__conv(2, name='conv3_10/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_11_x1_bn = self.__batch_normalization(2, 'conv3_11/x1/bn', num_features=448, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_11_x1 = self.__conv(2, name='conv3_11/x1', in_channels=448, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_11_x2_bn = self.__batch_normalization(2, 'conv3_11/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_11_x2 = self.__conv(2, name='conv3_11/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_12_x1_bn = self.__batch_normalization(2, 'conv3_12/x1/bn', num_features=480, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_12_x1 = self.__conv(2, name='conv3_12/x1', in_channels=480, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv3_12_x2_bn = self.__batch_normalization(2, 'conv3_12/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv3_12_x2 = self.__conv(2, name='conv3_12/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv3_blk_bn = self.__batch_normalization(2, 'conv3_blk/bn', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_8_1 = self.__conv(2, name='conv_SE_1/8_1', in_channels=512, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv3_blk = self.__conv(2, name='conv3_blk', in_channels=512, out_channels=256, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv_SE_1_8_2 = self.__conv(2, name='conv_SE_1/8_2', in_channels=32, out_channels=512, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv4_1_x1_bn = self.__batch_normalization(2, 'conv4_1/x1/bn', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_1_x1 = self.__conv(2, name='conv4_1/x1', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_1_x2_bn = self.__batch_normalization(2, 'conv4_1/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_8 = self.__conv(2, name='conv_SE_1/8', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv4_1_x2 = self.__conv(2, name='conv4_1/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_SE_1_8 = self.__batch_normalization(2, 'bn_SE_1/8', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_2_x1_bn = self.__batch_normalization(2, 'conv4_2/x1/bn', num_features=288, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_2_x1 = self.__conv(2, name='conv4_2/x1', in_channels=288, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_2_x2_bn = self.__batch_normalization(2, 'conv4_2/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_2_x2 = self.__conv(2, name='conv4_2/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_3_x1_bn = self.__batch_normalization(2, 'conv4_3/x1/bn', num_features=320, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_3_x1 = self.__conv(2, name='conv4_3/x1', in_channels=320, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_3_x2_bn = self.__batch_normalization(2, 'conv4_3/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_3_x2 = self.__conv(2, name='conv4_3/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_4_x1_bn = self.__batch_normalization(2, 'conv4_4/x1/bn', num_features=352, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_4_x1 = self.__conv(2, name='conv4_4/x1', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_4_x2_bn = self.__batch_normalization(2, 'conv4_4/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_4_x2 = self.__conv(2, name='conv4_4/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_5_x1_bn = self.__batch_normalization(2, 'conv4_5/x1/bn', num_features=384, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_5_x1 = self.__conv(2, name='conv4_5/x1', in_channels=384, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_5_x2_bn = self.__batch_normalization(2, 'conv4_5/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_5_x2 = self.__conv(2, name='conv4_5/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_6_x1_bn = self.__batch_normalization(2, 'conv4_6/x1/bn', num_features=416, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_6_x1 = self.__conv(2, name='conv4_6/x1', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_6_x2_bn = self.__batch_normalization(2, 'conv4_6/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_6_x2 = self.__conv(2, name='conv4_6/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_7_x1_bn = self.__batch_normalization(2, 'conv4_7/x1/bn', num_features=448, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_7_x1 = self.__conv(2, name='conv4_7/x1', in_channels=448, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_7_x2_bn = self.__batch_normalization(2, 'conv4_7/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_7_x2 = self.__conv(2, name='conv4_7/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_8_x1_bn = self.__batch_normalization(2, 'conv4_8/x1/bn', num_features=480, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_8_x1 = self.__conv(2, name='conv4_8/x1', in_channels=480, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_8_x2_bn = self.__batch_normalization(2, 'conv4_8/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_8_x2 = self.__conv(2, name='conv4_8/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_9_x1_bn = self.__batch_normalization(2, 'conv4_9/x1/bn', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_9_x1 = self.__conv(2, name='conv4_9/x1', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_9_x2_bn = self.__batch_normalization(2, 'conv4_9/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_9_x2 = self.__conv(2, name='conv4_9/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_10_x1_bn = self.__batch_normalization(2, 'conv4_10/x1/bn', num_features=544, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_10_x1 = self.__conv(2, name='conv4_10/x1', in_channels=544, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_10_x2_bn = self.__batch_normalization(2, 'conv4_10/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_10_x2 = self.__conv(2, name='conv4_10/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_11_x1_bn = self.__batch_normalization(2, 'conv4_11/x1/bn', num_features=576, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_11_x1 = self.__conv(2, name='conv4_11/x1', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_11_x2_bn = self.__batch_normalization(2, 'conv4_11/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_11_x2 = self.__conv(2, name='conv4_11/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_12_x1_bn = self.__batch_normalization(2, 'conv4_12/x1/bn', num_features=608, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_12_x1 = self.__conv(2, name='conv4_12/x1', in_channels=608, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_12_x2_bn = self.__batch_normalization(2, 'conv4_12/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_12_x2 = self.__conv(2, name='conv4_12/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_13_x1_bn = self.__batch_normalization(2, 'conv4_13/x1/bn', num_features=640, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_13_x1 = self.__conv(2, name='conv4_13/x1', in_channels=640, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_13_x2_bn = self.__batch_normalization(2, 'conv4_13/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_13_x2 = self.__conv(2, name='conv4_13/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_14_x1_bn = self.__batch_normalization(2, 'conv4_14/x1/bn', num_features=672, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_14_x1 = self.__conv(2, name='conv4_14/x1', in_channels=672, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_14_x2_bn = self.__batch_normalization(2, 'conv4_14/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_14_x2 = self.__conv(2, name='conv4_14/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_15_x1_bn = self.__batch_normalization(2, 'conv4_15/x1/bn', num_features=704, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_15_x1 = self.__conv(2, name='conv4_15/x1', in_channels=704, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_15_x2_bn = self.__batch_normalization(2, 'conv4_15/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_15_x2 = self.__conv(2, name='conv4_15/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_16_x1_bn = self.__batch_normalization(2, 'conv4_16/x1/bn', num_features=736, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_16_x1 = self.__conv(2, name='conv4_16/x1', in_channels=736, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_16_x2_bn = self.__batch_normalization(2, 'conv4_16/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_16_x2 = self.__conv(2, name='conv4_16/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_17_x1_bn = self.__batch_normalization(2, 'conv4_17/x1/bn', num_features=768, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_17_x1 = self.__conv(2, name='conv4_17/x1', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_17_x2_bn = self.__batch_normalization(2, 'conv4_17/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_17_x2 = self.__conv(2, name='conv4_17/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_18_x1_bn = self.__batch_normalization(2, 'conv4_18/x1/bn', num_features=800, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_18_x1 = self.__conv(2, name='conv4_18/x1', in_channels=800, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_18_x2_bn = self.__batch_normalization(2, 'conv4_18/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_18_x2 = self.__conv(2, name='conv4_18/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_19_x1_bn = self.__batch_normalization(2, 'conv4_19/x1/bn', num_features=832, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_19_x1 = self.__conv(2, name='conv4_19/x1', in_channels=832, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_19_x2_bn = self.__batch_normalization(2, 'conv4_19/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_19_x2 = self.__conv(2, name='conv4_19/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_20_x1_bn = self.__batch_normalization(2, 'conv4_20/x1/bn', num_features=864, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_20_x1 = self.__conv(2, name='conv4_20/x1', in_channels=864, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_20_x2_bn = self.__batch_normalization(2, 'conv4_20/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_20_x2 = self.__conv(2, name='conv4_20/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_21_x1_bn = self.__batch_normalization(2, 'conv4_21/x1/bn', num_features=896, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_21_x1 = self.__conv(2, name='conv4_21/x1', in_channels=896, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_21_x2_bn = self.__batch_normalization(2, 'conv4_21/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_21_x2 = self.__conv(2, name='conv4_21/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_22_x1_bn = self.__batch_normalization(2, 'conv4_22/x1/bn', num_features=928, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_22_x1 = self.__conv(2, name='conv4_22/x1', in_channels=928, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_22_x2_bn = self.__batch_normalization(2, 'conv4_22/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_22_x2 = self.__conv(2, name='conv4_22/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_23_x1_bn = self.__batch_normalization(2, 'conv4_23/x1/bn', num_features=960, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_23_x1 = self.__conv(2, name='conv4_23/x1', in_channels=960, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_23_x2_bn = self.__batch_normalization(2, 'conv4_23/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_23_x2 = self.__conv(2, name='conv4_23/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_24_x1_bn = self.__batch_normalization(2, 'conv4_24/x1/bn', num_features=992, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_24_x1 = self.__conv(2, name='conv4_24/x1', in_channels=992, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv4_24_x2_bn = self.__batch_normalization(2, 'conv4_24/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv4_24_x2 = self.__conv(2, name='conv4_24/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv4_blk_bn = self.__batch_normalization(2, 'conv4_blk/bn', num_features=1024, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_16_1 = self.__conv(2, name='conv_SE_1/16_1', in_channels=1024, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv4_blk = self.__conv(2, name='conv4_blk', in_channels=1024, out_channels=512, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv_SE_1_16_2 = self.__conv(2, name='conv_SE_1/16_2', in_channels=64, out_channels=1024, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv5_1_x1_bn = self.__batch_normalization(2, 'conv5_1/x1/bn', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_1_x1 = self.__conv(2, name='conv5_1/x1', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_1_x2_bn = self.__batch_normalization(2, 'conv5_1/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_SE_1_16 = self.__conv(2, name='conv_SE_1/16', in_channels=1024, out_channels=256, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv5_1_x2 = self.__conv(2, name='conv5_1/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_SE_1_16 = self.__batch_normalization(2, 'bn_SE_1/16', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_2_x1_bn = self.__batch_normalization(2, 'conv5_2/x1/bn', num_features=544, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_2_x1 = self.__conv(2, name='conv5_2/x1', in_channels=544, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_2_x2_bn = self.__batch_normalization(2, 'conv5_2/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_2_x2 = self.__conv(2, name='conv5_2/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_3_x1_bn = self.__batch_normalization(2, 'conv5_3/x1/bn', num_features=576, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_3_x1 = self.__conv(2, name='conv5_3/x1', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_3_x2_bn = self.__batch_normalization(2, 'conv5_3/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_3_x2 = self.__conv(2, name='conv5_3/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_4_x1_bn = self.__batch_normalization(2, 'conv5_4/x1/bn', num_features=608, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_4_x1 = self.__conv(2, name='conv5_4/x1', in_channels=608, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_4_x2_bn = self.__batch_normalization(2, 'conv5_4/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_4_x2 = self.__conv(2, name='conv5_4/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_5_x1_bn = self.__batch_normalization(2, 'conv5_5/x1/bn', num_features=640, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_5_x1 = self.__conv(2, name='conv5_5/x1', in_channels=640, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_5_x2_bn = self.__batch_normalization(2, 'conv5_5/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_5_x2 = self.__conv(2, name='conv5_5/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_6_x1_bn = self.__batch_normalization(2, 'conv5_6/x1/bn', num_features=672, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_6_x1 = self.__conv(2, name='conv5_6/x1', in_channels=672, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_6_x2_bn = self.__batch_normalization(2, 'conv5_6/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_6_x2 = self.__conv(2, name='conv5_6/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_7_x1_bn = self.__batch_normalization(2, 'conv5_7/x1/bn', num_features=704, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_7_x1 = self.__conv(2, name='conv5_7/x1', in_channels=704, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_7_x2_bn = self.__batch_normalization(2, 'conv5_7/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_7_x2 = self.__conv(2, name='conv5_7/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_8_x1_bn = self.__batch_normalization(2, 'conv5_8/x1/bn', num_features=736, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_8_x1 = self.__conv(2, name='conv5_8/x1', in_channels=736, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_8_x2_bn = self.__batch_normalization(2, 'conv5_8/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_8_x2 = self.__conv(2, name='conv5_8/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_9_x1_bn = self.__batch_normalization(2, 'conv5_9/x1/bn', num_features=768, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_9_x1 = self.__conv(2, name='conv5_9/x1', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_9_x2_bn = self.__batch_normalization(2, 'conv5_9/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_9_x2 = self.__conv(2, name='conv5_9/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_10_x1_bn = self.__batch_normalization(2, 'conv5_10/x1/bn', num_features=800, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_10_x1 = self.__conv(2, name='conv5_10/x1', in_channels=800, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_10_x2_bn = self.__batch_normalization(2, 'conv5_10/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_10_x2 = self.__conv(2, name='conv5_10/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_11_x1_bn = self.__batch_normalization(2, 'conv5_11/x1/bn', num_features=832, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_11_x1 = self.__conv(2, name='conv5_11/x1', in_channels=832, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_11_x2_bn = self.__batch_normalization(2, 'conv5_11/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_11_x2 = self.__conv(2, name='conv5_11/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_12_x1_bn = self.__batch_normalization(2, 'conv5_12/x1/bn', num_features=864, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_12_x1 = self.__conv(2, name='conv5_12/x1', in_channels=864, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_12_x2_bn = self.__batch_normalization(2, 'conv5_12/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_12_x2 = self.__conv(2, name='conv5_12/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_13_x1_bn = self.__batch_normalization(2, 'conv5_13/x1/bn', num_features=896, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_13_x1 = self.__conv(2, name='conv5_13/x1', in_channels=896, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_13_x2_bn = self.__batch_normalization(2, 'conv5_13/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_13_x2 = self.__conv(2, name='conv5_13/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_14_x1_bn = self.__batch_normalization(2, 'conv5_14/x1/bn', num_features=928, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_14_x1 = self.__conv(2, name='conv5_14/x1', in_channels=928, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_14_x2_bn = self.__batch_normalization(2, 'conv5_14/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_14_x2 = self.__conv(2, name='conv5_14/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_15_x1_bn = self.__batch_normalization(2, 'conv5_15/x1/bn', num_features=960, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_15_x1 = self.__conv(2, name='conv5_15/x1', in_channels=960, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_15_x2_bn = self.__batch_normalization(2, 'conv5_15/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_15_x2 = self.__conv(2, name='conv5_15/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv5_16_x1_bn = self.__batch_normalization(2, 'conv5_16/x1/bn', num_features=992, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_16_x1 = self.__conv(2, name='conv5_16/x1', in_channels=992, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv5_16_x2_bn = self.__batch_normalization(2, 'conv5_16/x2/bn', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv5_16_x2 = self.__conv(2, name='conv5_16/x2', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv_SE_1_32_1 = self.__conv(2, name='conv_SE_1/32_1', in_channels=1024, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv_SE_1_32_2 = self.__conv(2, name='conv_SE_1/32_2', in_channels=64, out_channels=1024, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv_1_32_1d = self.__conv(2, name='conv_1/32_1d', in_channels=1024, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_32_1d = self.__batch_normalization(2, 'bn_1/32_1d', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_32_2d = self.__conv(2, name='conv_1/32_2d', in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_32_2d = self.__batch_normalization(2, 'bn_1/32_2d', num_features=512, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_32_3d = self.__conv(2, name='conv_1/32_3d', in_channels=512, out_channels=256, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.bn_1_32_3d = self.__batch_normalization(2, 'bn_1/32_3d', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_1_16d = self.__batch_normalization(2, 'bn_1/16d', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_16_1d = self.__conv(2, name='conv_1/16_1d', in_channels=512, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_16_1d = self.__batch_normalization(2, 'bn_1/16_1d', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_16_2d = self.__conv(2, name='conv_1/16_2d', in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_16_2d = self.__batch_normalization(2, 'bn_1/16_2d', num_features=256, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_16_3d = self.__conv(2, name='conv_1/16_3d', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.bn_1_16_3d = self.__batch_normalization(2, 'bn_1/16_3d', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_1_8d = self.__batch_normalization(2, 'bn_1/8d', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_8_1d = self.__conv(2, name='conv_1/8_1d', in_channels=256, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_8_1d = self.__batch_normalization(2, 'bn_1/8_1d', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_8_2d = self.__conv(2, name='conv_1/8_2d', in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_8_2d = self.__batch_normalization(2, 'bn_1/8_2d', num_features=128, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_8_3d = self.__conv(2, name='conv_1/8_3d', in_channels=128, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.bn_1_8_3d = self.__batch_normalization(2, 'bn_1/8_3d', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_1_4d = self.__batch_normalization(2, 'bn_1/4d', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_4_1d = self.__conv(2, name='conv_1/4_1d', in_channels=128, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_4_1d = self.__batch_normalization(2, 'bn_1/4_1d', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_4_2d = self.__conv(2, name='conv_1/4_2d', in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_1_4_2d = self.__batch_normalization(2, 'bn_1/4_2d', num_features=64, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_1_4_3d = self.__conv(2, name='conv_1/4_3d', in_channels=64, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.bn_1_4_3d = self.__batch_normalization(2, 'bn_1/4_3d', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.pred_1_4 = self.__conv(2, name='pred_1/4', in_channels=32, out_channels=1, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv_atrous1_1 = self.__conv(2, name='conv_atrous1_1', in_channels=6, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous2_1 = self.__conv(2, name='conv_atrous2_1', in_channels=6, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous3_1 = self.__conv(2, name='conv_atrous3_1', in_channels=6, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_atrous1_1 = self.__batch_normalization(2, 'bn_atrous1_1', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous2_1 = self.__batch_normalization(2, 'bn_atrous2_1', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous3_1 = self.__batch_normalization(2, 'bn_atrous3_1', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_atrous1_2 = self.__conv(2, name='conv_atrous1_2', in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous2_2 = self.__conv(2, name='conv_atrous2_2', in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous3_2 = self.__conv(2, name='conv_atrous3_2', in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_atrous1_2 = self.__batch_normalization(2, 'bn_atrous1_2', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous2_2 = self.__batch_normalization(2, 'bn_atrous2_2', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous3_2 = self.__batch_normalization(2, 'bn_atrous3_2', num_features=32, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_atrous1_3 = self.__conv(2, name='conv_atrous1_3', in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous2_3 = self.__conv(2, name='conv_atrous2_3', in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv_atrous3_3 = self.__conv(2, name='conv_atrous3_3', in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.bn_atrous1_3 = self.__batch_normalization(2, 'bn_atrous1_3', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous2_3 = self.__batch_normalization(2, 'bn_atrous2_3', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.bn_atrous3_3 = self.__batch_normalization(2, 'bn_atrous3_3', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.conv_s2_down = self.__conv(2, name='conv_s2_down', in_channels=48, out_channels=3, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv_s2_up = self.__conv(2, name='conv_s2_up', in_channels=3, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.conv_p1_1 = self.__conv(2, name='conv_p1_1', in_channels=48, out_channels=16, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.bn_p1_1 = self.__batch_normalization(2, 'bn_p1_1', num_features=16, eps=9.999999747378752e-06, momentum=0.0)
        self.pred_step_2 = self.__conv(2, name='pred_step_2', in_channels=16, out_channels=1, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=True)
        self.deconv_1_16d = nn.ConvTranspose2D(in_channels=256, out_channels=256, kernel_size=2, stride=2, bias=False)
        self.deconv_1_8d = nn.ConvTranspose2D(in_channels=128, out_channels=256, kernel_size=2, stride=2, bias=False)
        self.deconv_1_4d = nn.ConvTranspose2D(in_channels=64, out_channels=256, kernel_size=2, stride=2, bias=False)
        self.pred_step_1 = nn.ConvTranspose2D(in_channels=1, out_channels=1, kernel_size=4, stride=4, bias=False)

    def forward(self, x):
        concat_input    = torch.cat((x, x,), 1)
        conv1_pad       = F.pad(concat_input, (3, 3, 3, 3))

        conv1           = self.conv1(conv1_pad)
        conv1_bn        = self.conv1_bn(conv1)
        relu1           = F.relu(conv1_bn)
        pool1_pad       = F.pad(relu1, (1, 1, 1, 1), value=float('-inf'))
        pool1, pool1_idx = F.max_pool2d(pool1_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False, return_indices=True)

        conv2_1_x1_bn   = self.conv2_1_x1_bn(pool1)
        relu2_1_x1      = F.relu(conv2_1_x1_bn)
        conv2_1_x1      = self.conv2_1_x1(relu2_1_x1)
        conv2_1_x2_bn   = self.conv2_1_x2_bn(conv2_1_x1)
        relu2_1_x2      = F.relu(conv2_1_x2_bn)
        conv2_1_x2_pad  = F.pad(relu2_1_x2, (1, 1, 1, 1))
        conv2_1_x2      = self.conv2_1_x2(conv2_1_x2_pad)

        concat_2_1      = torch.cat((pool1, conv2_1_x2,), 1)

        conv2_2_x1_bn   = self.conv2_2_x1_bn(concat_2_1)
        relu2_2_x1      = F.relu(conv2_2_x1_bn)
        conv2_2_x1      = self.conv2_2_x1(relu2_2_x1)
        conv2_2_x2_bn   = self.conv2_2_x2_bn(conv2_2_x1)
        relu2_2_x2      = F.relu(conv2_2_x2_bn)
        conv2_2_x2_pad  = F.pad(relu2_2_x2, (1, 1, 1, 1))
        conv2_2_x2      = self.conv2_2_x2(conv2_2_x2_pad)

        concat_2_2      = torch.cat((concat_2_1, conv2_2_x2,), 1)

        conv2_3_x1_bn   = self.conv2_3_x1_bn(concat_2_2)
        relu2_3_x1      = F.relu(conv2_3_x1_bn)
        conv2_3_x1      = self.conv2_3_x1(relu2_3_x1)
        conv2_3_x2_bn   = self.conv2_3_x2_bn(conv2_3_x1)
        relu2_3_x2      = F.relu(conv2_3_x2_bn)
        conv2_3_x2_pad  = F.pad(relu2_3_x2, (1, 1, 1, 1))
        conv2_3_x2      = self.conv2_3_x2(conv2_3_x2_pad)
        concat_2_3      = torch.cat((concat_2_2, conv2_3_x2,), 1)
        conv2_4_x1_bn   = self.conv2_4_x1_bn(concat_2_3)
        relu2_4_x1      = F.relu(conv2_4_x1_bn)
        conv2_4_x1      = self.conv2_4_x1(relu2_4_x1)
        conv2_4_x2_bn   = self.conv2_4_x2_bn(conv2_4_x1)
        relu2_4_x2      = F.relu(conv2_4_x2_bn)
        conv2_4_x2_pad  = F.pad(relu2_4_x2, (1, 1, 1, 1))
        conv2_4_x2      = self.conv2_4_x2(conv2_4_x2_pad)
        concat_2_4      = torch.cat((concat_2_3, conv2_4_x2,), 1)
        conv2_5_x1_bn   = self.conv2_5_x1_bn(concat_2_4)
        relu2_5_x1      = F.relu(conv2_5_x1_bn)
        conv2_5_x1      = self.conv2_5_x1(relu2_5_x1)
        conv2_5_x2_bn   = self.conv2_5_x2_bn(conv2_5_x1)
        relu2_5_x2      = F.relu(conv2_5_x2_bn)
        conv2_5_x2_pad  = F.pad(relu2_5_x2, (1, 1, 1, 1))
        conv2_5_x2      = self.conv2_5_x2(conv2_5_x2_pad)
        concat_2_5      = torch.cat((concat_2_4, conv2_5_x2,), 1)
        conv2_6_x1_bn   = self.conv2_6_x1_bn(concat_2_5)
        relu2_6_x1      = F.relu(conv2_6_x1_bn)
        conv2_6_x1      = self.conv2_6_x1(relu2_6_x1)
        conv2_6_x2_bn   = self.conv2_6_x2_bn(conv2_6_x1)
        relu2_6_x2      = F.relu(conv2_6_x2_bn)
        conv2_6_x2_pad  = F.pad(relu2_6_x2, (1, 1, 1, 1))
        conv2_6_x2      = self.conv2_6_x2(conv2_6_x2_pad)

        concat_2_6      = torch.cat((concat_2_5, conv2_6_x2,), 1)
        
        conv2_blk_bn    = self.conv2_blk_bn(concat_2_6)
        relu2_blk       = F.relu(conv2_blk_bn)
        conv2_blk       = self.conv2_blk(relu2_blk)
        pool2           = F.avg_pool2d(conv2_blk, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=True, count_include_pad=False)
        conv3_1_x1_bn   = self.conv3_1_x1_bn(pool2)
        relu3_1_x1      = F.relu(conv3_1_x1_bn)
        conv3_1_x1      = self.conv3_1_x1(relu3_1_x1)
        conv3_1_x2_bn   = self.conv3_1_x2_bn(conv3_1_x1)
        relu3_1_x2      = F.relu(conv3_1_x2_bn)
        conv3_1_x2_pad  = F.pad(relu3_1_x2, (1, 1, 1, 1))
        conv3_1_x2      = self.conv3_1_x2(conv3_1_x2_pad)
        concat_3_1      = torch.cat((pool2, conv3_1_x2,), 1)
        conv3_2_x1_bn   = self.conv3_2_x1_bn(concat_3_1)
        relu3_2_x1      = F.relu(conv3_2_x1_bn)
        conv3_2_x1      = self.conv3_2_x1(relu3_2_x1)
        conv3_2_x2_bn   = self.conv3_2_x2_bn(conv3_2_x1)
        relu3_2_x2      = F.relu(conv3_2_x2_bn)
        conv3_2_x2_pad  = F.pad(relu3_2_x2, (1, 1, 1, 1))
        conv3_2_x2      = self.conv3_2_x2(conv3_2_x2_pad)
        concat_3_2      = torch.cat((concat_3_1, conv3_2_x2,), 1)
        conv3_3_x1_bn   = self.conv3_3_x1_bn(concat_3_2)
        relu3_3_x1      = F.relu(conv3_3_x1_bn)
        conv3_3_x1      = self.conv3_3_x1(relu3_3_x1)
        conv3_3_x2_bn   = self.conv3_3_x2_bn(conv3_3_x1)
        relu3_3_x2      = F.relu(conv3_3_x2_bn)
        conv3_3_x2_pad  = F.pad(relu3_3_x2, (1, 1, 1, 1))
        conv3_3_x2      = self.conv3_3_x2(conv3_3_x2_pad)
        concat_3_3      = torch.cat((concat_3_2, conv3_3_x2,), 1)
        conv3_4_x1_bn   = self.conv3_4_x1_bn(concat_3_3)
        relu3_4_x1      = F.relu(conv3_4_x1_bn)
        conv3_4_x1      = self.conv3_4_x1(relu3_4_x1)
        conv3_4_x2_bn   = self.conv3_4_x2_bn(conv3_4_x1)
        relu3_4_x2      = F.relu(conv3_4_x2_bn)
        conv3_4_x2_pad  = F.pad(relu3_4_x2, (1, 1, 1, 1))
        conv3_4_x2      = self.conv3_4_x2(conv3_4_x2_pad)
        concat_3_4      = torch.cat((concat_3_3, conv3_4_x2,), 1)
        conv3_5_x1_bn   = self.conv3_5_x1_bn(concat_3_4)
        relu3_5_x1      = F.relu(conv3_5_x1_bn)
        conv3_5_x1      = self.conv3_5_x1(relu3_5_x1)
        conv3_5_x2_bn   = self.conv3_5_x2_bn(conv3_5_x1)
        relu3_5_x2      = F.relu(conv3_5_x2_bn)
        conv3_5_x2_pad  = F.pad(relu3_5_x2, (1, 1, 1, 1))
        conv3_5_x2      = self.conv3_5_x2(conv3_5_x2_pad)
        concat_3_5      = torch.cat((concat_3_4, conv3_5_x2,), 1)
        conv3_6_x1_bn   = self.conv3_6_x1_bn(concat_3_5)
        relu3_6_x1      = F.relu(conv3_6_x1_bn)
        conv3_6_x1      = self.conv3_6_x1(relu3_6_x1)
        conv3_6_x2_bn   = self.conv3_6_x2_bn(conv3_6_x1)
        relu3_6_x2      = F.relu(conv3_6_x2_bn)
        conv3_6_x2_pad  = F.pad(relu3_6_x2, (1, 1, 1, 1))
        conv3_6_x2      = self.conv3_6_x2(conv3_6_x2_pad)
        concat_3_6      = torch.cat((concat_3_5, conv3_6_x2,), 1)
        conv3_7_x1_bn   = self.conv3_7_x1_bn(concat_3_6)
        relu3_7_x1      = F.relu(conv3_7_x1_bn)
        conv3_7_x1      = self.conv3_7_x1(relu3_7_x1)
        conv3_7_x2_bn   = self.conv3_7_x2_bn(conv3_7_x1)
        relu3_7_x2      = F.relu(conv3_7_x2_bn)
        conv3_7_x2_pad  = F.pad(relu3_7_x2, (1, 1, 1, 1))
        conv3_7_x2      = self.conv3_7_x2(conv3_7_x2_pad)
        concat_3_7      = torch.cat((concat_3_6, conv3_7_x2,), 1)
        conv3_8_x1_bn   = self.conv3_8_x1_bn(concat_3_7)
        relu3_8_x1      = F.relu(conv3_8_x1_bn)
        conv3_8_x1      = self.conv3_8_x1(relu3_8_x1)
        conv3_8_x2_bn   = self.conv3_8_x2_bn(conv3_8_x1)
        relu3_8_x2      = F.relu(conv3_8_x2_bn)
        conv3_8_x2_pad  = F.pad(relu3_8_x2, (1, 1, 1, 1))
        conv3_8_x2      = self.conv3_8_x2(conv3_8_x2_pad)
        concat_3_8      = torch.cat((concat_3_7, conv3_8_x2,), 1)
        conv3_9_x1_bn   = self.conv3_9_x1_bn(concat_3_8)
        relu3_9_x1      = F.relu(conv3_9_x1_bn)
        conv3_9_x1      = self.conv3_9_x1(relu3_9_x1)
        conv3_9_x2_bn   = self.conv3_9_x2_bn(conv3_9_x1)
        relu3_9_x2      = F.relu(conv3_9_x2_bn)
        conv3_9_x2_pad  = F.pad(relu3_9_x2, (1, 1, 1, 1))
        conv3_9_x2      = self.conv3_9_x2(conv3_9_x2_pad)
        concat_3_9      = torch.cat((concat_3_8, conv3_9_x2,), 1)
        conv3_10_x1_bn  = self.conv3_10_x1_bn(concat_3_9)
        relu3_10_x1     = F.relu(conv3_10_x1_bn)
        conv3_10_x1     = self.conv3_10_x1(relu3_10_x1)
        conv3_10_x2_bn  = self.conv3_10_x2_bn(conv3_10_x1)
        relu3_10_x2     = F.relu(conv3_10_x2_bn)
        conv3_10_x2_pad = F.pad(relu3_10_x2, (1, 1, 1, 1))
        conv3_10_x2     = self.conv3_10_x2(conv3_10_x2_pad)
        concat_3_10     = torch.cat((concat_3_9, conv3_10_x2,), 1)
        conv3_11_x1_bn  = self.conv3_11_x1_bn(concat_3_10)
        relu3_11_x1     = F.relu(conv3_11_x1_bn)
        conv3_11_x1     = self.conv3_11_x1(relu3_11_x1)
        conv3_11_x2_bn  = self.conv3_11_x2_bn(conv3_11_x1)
        relu3_11_x2     = F.relu(conv3_11_x2_bn)
        conv3_11_x2_pad = F.pad(relu3_11_x2, (1, 1, 1, 1))
        conv3_11_x2     = self.conv3_11_x2(conv3_11_x2_pad)
        concat_3_11     = torch.cat((concat_3_10, conv3_11_x2,), 1)
        conv3_12_x1_bn  = self.conv3_12_x1_bn(concat_3_11)
        relu3_12_x1     = F.relu(conv3_12_x1_bn)
        conv3_12_x1     = self.conv3_12_x1(relu3_12_x1)
        conv3_12_x2_bn  = self.conv3_12_x2_bn(conv3_12_x1)
        relu3_12_x2     = F.relu(conv3_12_x2_bn)
        conv3_12_x2_pad = F.pad(relu3_12_x2, (1, 1, 1, 1))
        conv3_12_x2     = self.conv3_12_x2(conv3_12_x2_pad)
        concat_3_12     = torch.cat((concat_3_11, conv3_12_x2,), 1)
        conv3_blk_bn    = self.conv3_blk_bn(concat_3_12)
        relu3_blk       = F.relu(conv3_blk_bn)
        conv3_blk       = self.conv3_blk(relu3_blk)
        pool3           = F.avg_pool2d(conv3_blk, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=True, count_include_pad=False)
        conv4_1_x1_bn   = self.conv4_1_x1_bn(pool3)
        relu4_1_x1      = F.relu(conv4_1_x1_bn)
        conv4_1_x1      = self.conv4_1_x1(relu4_1_x1)
        conv4_1_x2_bn   = self.conv4_1_x2_bn(conv4_1_x1)
        relu4_1_x2      = F.relu(conv4_1_x2_bn)
        conv4_1_x2_pad  = F.pad(relu4_1_x2, (1, 1, 1, 1))
        conv4_1_x2      = self.conv4_1_x2(conv4_1_x2_pad)
        concat_4_1      = torch.cat((pool3, conv4_1_x2,), 1)
        conv4_2_x1_bn   = self.conv4_2_x1_bn(concat_4_1)
        relu4_2_x1      = F.relu(conv4_2_x1_bn)
        conv4_2_x1      = self.conv4_2_x1(relu4_2_x1)
        conv4_2_x2_bn   = self.conv4_2_x2_bn(conv4_2_x1)
        relu4_2_x2      = F.relu(conv4_2_x2_bn)
        conv4_2_x2_pad  = F.pad(relu4_2_x2, (1, 1, 1, 1))
        conv4_2_x2      = self.conv4_2_x2(conv4_2_x2_pad)
        concat_4_2      = torch.cat((concat_4_1, conv4_2_x2,), 1)
        conv4_3_x1_bn   = self.conv4_3_x1_bn(concat_4_2)
        relu4_3_x1      = F.relu(conv4_3_x1_bn)
        conv4_3_x1      = self.conv4_3_x1(relu4_3_x1)
        conv4_3_x2_bn   = self.conv4_3_x2_bn(conv4_3_x1)
        relu4_3_x2      = F.relu(conv4_3_x2_bn)
        conv4_3_x2_pad  = F.pad(relu4_3_x2, (1, 1, 1, 1))
        conv4_3_x2      = self.conv4_3_x2(conv4_3_x2_pad)
        concat_4_3      = torch.cat((concat_4_2, conv4_3_x2,), 1)
        conv4_4_x1_bn   = self.conv4_4_x1_bn(concat_4_3)
        relu4_4_x1      = F.relu(conv4_4_x1_bn)
        conv4_4_x1      = self.conv4_4_x1(relu4_4_x1)
        conv4_4_x2_bn   = self.conv4_4_x2_bn(conv4_4_x1)
        relu4_4_x2      = F.relu(conv4_4_x2_bn)
        conv4_4_x2_pad  = F.pad(relu4_4_x2, (1, 1, 1, 1))
        conv4_4_x2      = self.conv4_4_x2(conv4_4_x2_pad)
        concat_4_4      = torch.cat((concat_4_3, conv4_4_x2,), 1)
        conv4_5_x1_bn   = self.conv4_5_x1_bn(concat_4_4)
        relu4_5_x1      = F.relu(conv4_5_x1_bn)
        conv4_5_x1      = self.conv4_5_x1(relu4_5_x1)
        conv4_5_x2_bn   = self.conv4_5_x2_bn(conv4_5_x1)
        relu4_5_x2      = F.relu(conv4_5_x2_bn)
        conv4_5_x2_pad  = F.pad(relu4_5_x2, (1, 1, 1, 1))
        conv4_5_x2      = self.conv4_5_x2(conv4_5_x2_pad)
        concat_4_5      = torch.cat((concat_4_4, conv4_5_x2,), 1)
        conv4_6_x1_bn   = self.conv4_6_x1_bn(concat_4_5)
        relu4_6_x1      = F.relu(conv4_6_x1_bn)
        conv4_6_x1      = self.conv4_6_x1(relu4_6_x1)
        conv4_6_x2_bn   = self.conv4_6_x2_bn(conv4_6_x1)
        relu4_6_x2      = F.relu(conv4_6_x2_bn)
        conv4_6_x2_pad  = F.pad(relu4_6_x2, (1, 1, 1, 1))
        conv4_6_x2      = self.conv4_6_x2(conv4_6_x2_pad)
        concat_4_6      = torch.cat((concat_4_5, conv4_6_x2,), 1)
        conv4_7_x1_bn   = self.conv4_7_x1_bn(concat_4_6)
        relu4_7_x1      = F.relu(conv4_7_x1_bn)
        conv4_7_x1      = self.conv4_7_x1(relu4_7_x1)
        conv4_7_x2_bn   = self.conv4_7_x2_bn(conv4_7_x1)
        relu4_7_x2      = F.relu(conv4_7_x2_bn)
        conv4_7_x2_pad  = F.pad(relu4_7_x2, (1, 1, 1, 1))
        conv4_7_x2      = self.conv4_7_x2(conv4_7_x2_pad)
        concat_4_7      = torch.cat((concat_4_6, conv4_7_x2,), 1)
        conv4_8_x1_bn   = self.conv4_8_x1_bn(concat_4_7)
        relu4_8_x1      = F.relu(conv4_8_x1_bn)
        conv4_8_x1      = self.conv4_8_x1(relu4_8_x1)
        conv4_8_x2_bn   = self.conv4_8_x2_bn(conv4_8_x1)
        relu4_8_x2      = F.relu(conv4_8_x2_bn)
        conv4_8_x2_pad  = F.pad(relu4_8_x2, (1, 1, 1, 1))
        conv4_8_x2      = self.conv4_8_x2(conv4_8_x2_pad)
        concat_4_8      = torch.cat((concat_4_7, conv4_8_x2,), 1)
        conv4_9_x1_bn   = self.conv4_9_x1_bn(concat_4_8)
        relu4_9_x1      = F.relu(conv4_9_x1_bn)
        conv4_9_x1      = self.conv4_9_x1(relu4_9_x1)
        conv4_9_x2_bn   = self.conv4_9_x2_bn(conv4_9_x1)
        relu4_9_x2      = F.relu(conv4_9_x2_bn)
        conv4_9_x2_pad  = F.pad(relu4_9_x2, (1, 1, 1, 1))
        conv4_9_x2      = self.conv4_9_x2(conv4_9_x2_pad)
        concat_4_9      = torch.cat((concat_4_8, conv4_9_x2,), 1)
        conv4_10_x1_bn  = self.conv4_10_x1_bn(concat_4_9)
        relu4_10_x1     = F.relu(conv4_10_x1_bn)
        conv4_10_x1     = self.conv4_10_x1(relu4_10_x1)
        conv4_10_x2_bn  = self.conv4_10_x2_bn(conv4_10_x1)
        relu4_10_x2     = F.relu(conv4_10_x2_bn)
        conv4_10_x2_pad = F.pad(relu4_10_x2, (1, 1, 1, 1))
        conv4_10_x2     = self.conv4_10_x2(conv4_10_x2_pad)
        concat_4_10     = torch.cat((concat_4_9, conv4_10_x2,), 1)
        conv4_11_x1_bn  = self.conv4_11_x1_bn(concat_4_10)
        relu4_11_x1     = F.relu(conv4_11_x1_bn)
        conv4_11_x1     = self.conv4_11_x1(relu4_11_x1)
        conv4_11_x2_bn  = self.conv4_11_x2_bn(conv4_11_x1)
        relu4_11_x2     = F.relu(conv4_11_x2_bn)
        conv4_11_x2_pad = F.pad(relu4_11_x2, (1, 1, 1, 1))
        conv4_11_x2     = self.conv4_11_x2(conv4_11_x2_pad)
        concat_4_11     = torch.cat((concat_4_10, conv4_11_x2,), 1)
        conv4_12_x1_bn  = self.conv4_12_x1_bn(concat_4_11)
        relu4_12_x1     = F.relu(conv4_12_x1_bn)
        conv4_12_x1     = self.conv4_12_x1(relu4_12_x1)
        conv4_12_x2_bn  = self.conv4_12_x2_bn(conv4_12_x1)
        relu4_12_x2     = F.relu(conv4_12_x2_bn)
        conv4_12_x2_pad = F.pad(relu4_12_x2, (1, 1, 1, 1))
        conv4_12_x2     = self.conv4_12_x2(conv4_12_x2_pad)
        concat_4_12     = torch.cat((concat_4_11, conv4_12_x2,), 1)
        conv4_13_x1_bn  = self.conv4_13_x1_bn(concat_4_12)
        relu4_13_x1     = F.relu(conv4_13_x1_bn)
        conv4_13_x1     = self.conv4_13_x1(relu4_13_x1)
        conv4_13_x2_bn  = self.conv4_13_x2_bn(conv4_13_x1)
        relu4_13_x2     = F.relu(conv4_13_x2_bn)
        conv4_13_x2_pad = F.pad(relu4_13_x2, (1, 1, 1, 1))
        conv4_13_x2     = self.conv4_13_x2(conv4_13_x2_pad)
        concat_4_13     = torch.cat((concat_4_12, conv4_13_x2,), 1)
        conv4_14_x1_bn  = self.conv4_14_x1_bn(concat_4_13)
        relu4_14_x1     = F.relu(conv4_14_x1_bn)
        conv4_14_x1     = self.conv4_14_x1(relu4_14_x1)
        conv4_14_x2_bn  = self.conv4_14_x2_bn(conv4_14_x1)
        relu4_14_x2     = F.relu(conv4_14_x2_bn)
        conv4_14_x2_pad = F.pad(relu4_14_x2, (1, 1, 1, 1))
        conv4_14_x2     = self.conv4_14_x2(conv4_14_x2_pad)
        concat_4_14     = torch.cat((concat_4_13, conv4_14_x2,), 1)
        conv4_15_x1_bn  = self.conv4_15_x1_bn(concat_4_14)
        relu4_15_x1     = F.relu(conv4_15_x1_bn)
        conv4_15_x1     = self.conv4_15_x1(relu4_15_x1)
        conv4_15_x2_bn  = self.conv4_15_x2_bn(conv4_15_x1)
        relu4_15_x2     = F.relu(conv4_15_x2_bn)
        conv4_15_x2_pad = F.pad(relu4_15_x2, (1, 1, 1, 1))
        conv4_15_x2     = self.conv4_15_x2(conv4_15_x2_pad)
        concat_4_15     = torch.cat((concat_4_14, conv4_15_x2,), 1)
        conv4_16_x1_bn  = self.conv4_16_x1_bn(concat_4_15)
        relu4_16_x1     = F.relu(conv4_16_x1_bn)
        conv4_16_x1     = self.conv4_16_x1(relu4_16_x1)
        conv4_16_x2_bn  = self.conv4_16_x2_bn(conv4_16_x1)
        relu4_16_x2     = F.relu(conv4_16_x2_bn)
        conv4_16_x2_pad = F.pad(relu4_16_x2, (1, 1, 1, 1))
        conv4_16_x2     = self.conv4_16_x2(conv4_16_x2_pad)
        concat_4_16     = torch.cat((concat_4_15, conv4_16_x2,), 1)
        conv4_17_x1_bn  = self.conv4_17_x1_bn(concat_4_16)
        relu4_17_x1     = F.relu(conv4_17_x1_bn)
        conv4_17_x1     = self.conv4_17_x1(relu4_17_x1)
        conv4_17_x2_bn  = self.conv4_17_x2_bn(conv4_17_x1)
        relu4_17_x2     = F.relu(conv4_17_x2_bn)
        conv4_17_x2_pad = F.pad(relu4_17_x2, (1, 1, 1, 1))
        conv4_17_x2     = self.conv4_17_x2(conv4_17_x2_pad)
        concat_4_17     = torch.cat((concat_4_16, conv4_17_x2,), 1)
        conv4_18_x1_bn  = self.conv4_18_x1_bn(concat_4_17)
        relu4_18_x1     = F.relu(conv4_18_x1_bn)
        conv4_18_x1     = self.conv4_18_x1(relu4_18_x1)
        conv4_18_x2_bn  = self.conv4_18_x2_bn(conv4_18_x1)
        relu4_18_x2     = F.relu(conv4_18_x2_bn)
        conv4_18_x2_pad = F.pad(relu4_18_x2, (1, 1, 1, 1))
        conv4_18_x2     = self.conv4_18_x2(conv4_18_x2_pad)
        concat_4_18     = torch.cat((concat_4_17, conv4_18_x2,), 1)
        conv4_19_x1_bn  = self.conv4_19_x1_bn(concat_4_18)
        relu4_19_x1     = F.relu(conv4_19_x1_bn)
        conv4_19_x1     = self.conv4_19_x1(relu4_19_x1)
        conv4_19_x2_bn  = self.conv4_19_x2_bn(conv4_19_x1)
        relu4_19_x2     = F.relu(conv4_19_x2_bn)
        conv4_19_x2_pad = F.pad(relu4_19_x2, (1, 1, 1, 1))
        conv4_19_x2     = self.conv4_19_x2(conv4_19_x2_pad)
        concat_4_19     = torch.cat((concat_4_18, conv4_19_x2,), 1)
        conv4_20_x1_bn  = self.conv4_20_x1_bn(concat_4_19)
        relu4_20_x1     = F.relu(conv4_20_x1_bn)
        conv4_20_x1     = self.conv4_20_x1(relu4_20_x1)
        conv4_20_x2_bn  = self.conv4_20_x2_bn(conv4_20_x1)
        relu4_20_x2     = F.relu(conv4_20_x2_bn)
        conv4_20_x2_pad = F.pad(relu4_20_x2, (1, 1, 1, 1))
        conv4_20_x2     = self.conv4_20_x2(conv4_20_x2_pad)
        concat_4_20     = torch.cat((concat_4_19, conv4_20_x2,), 1)
        conv4_21_x1_bn  = self.conv4_21_x1_bn(concat_4_20)
        relu4_21_x1     = F.relu(conv4_21_x1_bn)
        conv4_21_x1     = self.conv4_21_x1(relu4_21_x1)
        conv4_21_x2_bn  = self.conv4_21_x2_bn(conv4_21_x1)
        relu4_21_x2     = F.relu(conv4_21_x2_bn)
        conv4_21_x2_pad = F.pad(relu4_21_x2, (1, 1, 1, 1))
        conv4_21_x2     = self.conv4_21_x2(conv4_21_x2_pad)
        concat_4_21     = torch.cat((concat_4_20, conv4_21_x2,), 1)
        conv4_22_x1_bn  = self.conv4_22_x1_bn(concat_4_21)
        relu4_22_x1     = F.relu(conv4_22_x1_bn)
        conv4_22_x1     = self.conv4_22_x1(relu4_22_x1)
        conv4_22_x2_bn  = self.conv4_22_x2_bn(conv4_22_x1)
        relu4_22_x2     = F.relu(conv4_22_x2_bn)
        conv4_22_x2_pad = F.pad(relu4_22_x2, (1, 1, 1, 1))
        conv4_22_x2     = self.conv4_22_x2(conv4_22_x2_pad)
        concat_4_22     = torch.cat((concat_4_21, conv4_22_x2,), 1)
        conv4_23_x1_bn  = self.conv4_23_x1_bn(concat_4_22)
        relu4_23_x1     = F.relu(conv4_23_x1_bn)
        conv4_23_x1     = self.conv4_23_x1(relu4_23_x1)
        conv4_23_x2_bn  = self.conv4_23_x2_bn(conv4_23_x1)
        relu4_23_x2     = F.relu(conv4_23_x2_bn)
        conv4_23_x2_pad = F.pad(relu4_23_x2, (1, 1, 1, 1))
        conv4_23_x2     = self.conv4_23_x2(conv4_23_x2_pad)
        concat_4_23     = torch.cat((concat_4_22, conv4_23_x2,), 1)
        conv4_24_x1_bn  = self.conv4_24_x1_bn(concat_4_23)
        relu4_24_x1     = F.relu(conv4_24_x1_bn)
        conv4_24_x1     = self.conv4_24_x1(relu4_24_x1)
        conv4_24_x2_bn  = self.conv4_24_x2_bn(conv4_24_x1)
        relu4_24_x2     = F.relu(conv4_24_x2_bn)
        conv4_24_x2_pad = F.pad(relu4_24_x2, (1, 1, 1, 1))
        conv4_24_x2     = self.conv4_24_x2(conv4_24_x2_pad)
        concat_4_24     = torch.cat((concat_4_23, conv4_24_x2,), 1)
        conv4_blk_bn    = self.conv4_blk_bn(concat_4_24)
        relu4_blk       = F.relu(conv4_blk_bn)
        conv4_blk       = self.conv4_blk(relu4_blk)
        pool4           = F.avg_pool2d(conv4_blk, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=True, count_include_pad=False)
        conv5_1_x1_bn   = self.conv5_1_x1_bn(pool4)
        relu5_1_x1      = F.relu(conv5_1_x1_bn)
        conv5_1_x1      = self.conv5_1_x1(relu5_1_x1)
        scale_SE_1_16   = concat_4_24 * reshape_SE_1_16
        conv5_1_x2_bn   = self.conv5_1_x2_bn(conv5_1_x1)
        conv_SE_1_16    = self.conv_SE_1_16(scale_SE_1_16)
        relu5_1_x2      = F.relu(conv5_1_x2_bn)
        prelu_SE_1_16   = F.prelu(conv_SE_1_16, torch.from_numpy(_weights_dict['prelu_SE_1/16']['weights']))
        conv5_1_x2_pad  = F.pad(relu5_1_x2, (1, 1, 1, 1))
        conv5_1_x2      = self.conv5_1_x2(conv5_1_x2_pad)
        concat_5_1      = torch.cat((pool4, conv5_1_x2,), 1)
        conv5_2_x1_bn   = self.conv5_2_x1_bn(concat_5_1)
        relu5_2_x1      = F.relu(conv5_2_x1_bn)
        conv5_2_x1      = self.conv5_2_x1(relu5_2_x1)
        conv5_2_x2_bn   = self.conv5_2_x2_bn(conv5_2_x1)
        relu5_2_x2      = F.relu(conv5_2_x2_bn)
        conv5_2_x2_pad  = F.pad(relu5_2_x2, (1, 1, 1, 1))
        conv5_2_x2      = self.conv5_2_x2(conv5_2_x2_pad)
        concat_5_2      = torch.cat((concat_5_1, conv5_2_x2,), 1)
        conv5_3_x1_bn   = self.conv5_3_x1_bn(concat_5_2)
        relu5_3_x1      = F.relu(conv5_3_x1_bn)
        conv5_3_x1      = self.conv5_3_x1(relu5_3_x1)
        conv5_3_x2_bn   = self.conv5_3_x2_bn(conv5_3_x1)
        relu5_3_x2      = F.relu(conv5_3_x2_bn)
        conv5_3_x2_pad  = F.pad(relu5_3_x2, (1, 1, 1, 1))
        conv5_3_x2      = self.conv5_3_x2(conv5_3_x2_pad)
        concat_5_3      = torch.cat((concat_5_2, conv5_3_x2,), 1)
        conv5_4_x1_bn   = self.conv5_4_x1_bn(concat_5_3)
        relu5_4_x1      = F.relu(conv5_4_x1_bn)
        conv5_4_x1      = self.conv5_4_x1(relu5_4_x1)
        conv5_4_x2_bn   = self.conv5_4_x2_bn(conv5_4_x1)
        relu5_4_x2      = F.relu(conv5_4_x2_bn)
        conv5_4_x2_pad  = F.pad(relu5_4_x2, (1, 1, 1, 1))
        conv5_4_x2      = self.conv5_4_x2(conv5_4_x2_pad)
        concat_5_4      = torch.cat((concat_5_3, conv5_4_x2,), 1)
        conv5_5_x1_bn   = self.conv5_5_x1_bn(concat_5_4)
        relu5_5_x1      = F.relu(conv5_5_x1_bn)
        conv5_5_x1      = self.conv5_5_x1(relu5_5_x1)
        conv5_5_x2_bn   = self.conv5_5_x2_bn(conv5_5_x1)
        relu5_5_x2      = F.relu(conv5_5_x2_bn)
        conv5_5_x2_pad  = F.pad(relu5_5_x2, (1, 1, 1, 1))
        conv5_5_x2      = self.conv5_5_x2(conv5_5_x2_pad)
        concat_5_5      = torch.cat((concat_5_4, conv5_5_x2,), 1)
        conv5_6_x1_bn   = self.conv5_6_x1_bn(concat_5_5)
        relu5_6_x1      = F.relu(conv5_6_x1_bn)
        conv5_6_x1      = self.conv5_6_x1(relu5_6_x1)
        conv5_6_x2_bn   = self.conv5_6_x2_bn(conv5_6_x1)
        relu5_6_x2      = F.relu(conv5_6_x2_bn)
        conv5_6_x2_pad  = F.pad(relu5_6_x2, (1, 1, 1, 1))
        conv5_6_x2      = self.conv5_6_x2(conv5_6_x2_pad)
        concat_5_6      = torch.cat((concat_5_5, conv5_6_x2,), 1)
        conv5_7_x1_bn   = self.conv5_7_x1_bn(concat_5_6)
        relu5_7_x1      = F.relu(conv5_7_x1_bn)
        conv5_7_x1      = self.conv5_7_x1(relu5_7_x1)
        conv5_7_x2_bn   = self.conv5_7_x2_bn(conv5_7_x1)
        relu5_7_x2      = F.relu(conv5_7_x2_bn)
        conv5_7_x2_pad  = F.pad(relu5_7_x2, (1, 1, 1, 1))
        conv5_7_x2      = self.conv5_7_x2(conv5_7_x2_pad)
        concat_5_7      = torch.cat((concat_5_6, conv5_7_x2,), 1)
        conv5_8_x1_bn   = self.conv5_8_x1_bn(concat_5_7)
        relu5_8_x1      = F.relu(conv5_8_x1_bn)
        conv5_8_x1      = self.conv5_8_x1(relu5_8_x1)
        conv5_8_x2_bn   = self.conv5_8_x2_bn(conv5_8_x1)
        relu5_8_x2      = F.relu(conv5_8_x2_bn)
        conv5_8_x2_pad  = F.pad(relu5_8_x2, (1, 1, 1, 1))
        conv5_8_x2      = self.conv5_8_x2(conv5_8_x2_pad)
        concat_5_8      = torch.cat((concat_5_7, conv5_8_x2,), 1)
        conv5_9_x1_bn   = self.conv5_9_x1_bn(concat_5_8)
        relu5_9_x1      = F.relu(conv5_9_x1_bn)
        conv5_9_x1      = self.conv5_9_x1(relu5_9_x1)
        conv5_9_x2_bn   = self.conv5_9_x2_bn(conv5_9_x1)
        relu5_9_x2      = F.relu(conv5_9_x2_bn)
        conv5_9_x2_pad  = F.pad(relu5_9_x2, (1, 1, 1, 1))
        conv5_9_x2      = self.conv5_9_x2(conv5_9_x2_pad)
        concat_5_9      = torch.cat((concat_5_8, conv5_9_x2,), 1)
        conv5_10_x1_bn  = self.conv5_10_x1_bn(concat_5_9)
        relu5_10_x1     = F.relu(conv5_10_x1_bn)
        conv5_10_x1     = self.conv5_10_x1(relu5_10_x1)
        conv5_10_x2_bn  = self.conv5_10_x2_bn(conv5_10_x1)
        relu5_10_x2     = F.relu(conv5_10_x2_bn)
        conv5_10_x2_pad = F.pad(relu5_10_x2, (1, 1, 1, 1))
        conv5_10_x2     = self.conv5_10_x2(conv5_10_x2_pad)
        concat_5_10     = torch.cat((concat_5_9, conv5_10_x2,), 1)
        conv5_11_x1_bn  = self.conv5_11_x1_bn(concat_5_10)
        relu5_11_x1     = F.relu(conv5_11_x1_bn)
        conv5_11_x1     = self.conv5_11_x1(relu5_11_x1)
        conv5_11_x2_bn  = self.conv5_11_x2_bn(conv5_11_x1)
        relu5_11_x2     = F.relu(conv5_11_x2_bn)
        conv5_11_x2_pad = F.pad(relu5_11_x2, (1, 1, 1, 1))
        conv5_11_x2     = self.conv5_11_x2(conv5_11_x2_pad)
        concat_5_11     = torch.cat((concat_5_10, conv5_11_x2,), 1)
        conv5_12_x1_bn  = self.conv5_12_x1_bn(concat_5_11)
        relu5_12_x1     = F.relu(conv5_12_x1_bn)
        conv5_12_x1     = self.conv5_12_x1(relu5_12_x1)
        conv5_12_x2_bn  = self.conv5_12_x2_bn(conv5_12_x1)
        relu5_12_x2     = F.relu(conv5_12_x2_bn)
        conv5_12_x2_pad = F.pad(relu5_12_x2, (1, 1, 1, 1))
        conv5_12_x2     = self.conv5_12_x2(conv5_12_x2_pad)
        concat_5_12     = torch.cat((concat_5_11, conv5_12_x2,), 1)
        conv5_13_x1_bn  = self.conv5_13_x1_bn(concat_5_12)
        relu5_13_x1     = F.relu(conv5_13_x1_bn)
        conv5_13_x1     = self.conv5_13_x1(relu5_13_x1)
        conv5_13_x2_bn  = self.conv5_13_x2_bn(conv5_13_x1)
        relu5_13_x2     = F.relu(conv5_13_x2_bn)
        conv5_13_x2_pad = F.pad(relu5_13_x2, (1, 1, 1, 1))
        conv5_13_x2     = self.conv5_13_x2(conv5_13_x2_pad)
        concat_5_13     = torch.cat((concat_5_12, conv5_13_x2,), 1)
        conv5_14_x1_bn  = self.conv5_14_x1_bn(concat_5_13)
        relu5_14_x1     = F.relu(conv5_14_x1_bn)
        conv5_14_x1     = self.conv5_14_x1(relu5_14_x1)
        conv5_14_x2_bn  = self.conv5_14_x2_bn(conv5_14_x1)
        relu5_14_x2     = F.relu(conv5_14_x2_bn)
        conv5_14_x2_pad = F.pad(relu5_14_x2, (1, 1, 1, 1))
        conv5_14_x2     = self.conv5_14_x2(conv5_14_x2_pad)
        concat_5_14     = torch.cat((concat_5_13, conv5_14_x2,), 1)
        conv5_15_x1_bn  = self.conv5_15_x1_bn(concat_5_14)
        relu5_15_x1     = F.relu(conv5_15_x1_bn)
        conv5_15_x1     = self.conv5_15_x1(relu5_15_x1)
        conv5_15_x2_bn  = self.conv5_15_x2_bn(conv5_15_x1)
        relu5_15_x2     = F.relu(conv5_15_x2_bn)
        conv5_15_x2_pad = F.pad(relu5_15_x2, (1, 1, 1, 1))
        conv5_15_x2     = self.conv5_15_x2(conv5_15_x2_pad)
        concat_5_15     = torch.cat((concat_5_14, conv5_15_x2,), 1)
        conv5_16_x1_bn  = self.conv5_16_x1_bn(concat_5_15)
        relu5_16_x1     = F.relu(conv5_16_x1_bn)
        conv5_16_x1     = self.conv5_16_x1(relu5_16_x1)
        conv5_16_x2_bn  = self.conv5_16_x2_bn(conv5_16_x1)
        relu5_16_x2     = F.relu(conv5_16_x2_bn)
        conv5_16_x2_pad = F.pad(relu5_16_x2, (1, 1, 1, 1))
        conv5_16_x2     = self.conv5_16_x2(conv5_16_x2_pad)
        concat_5_16     = torch.cat((concat_5_15, conv5_16_x2,), 1)

        ################ SECONDARY NETWORK (COARSE DECODER) STARTS HERE ################

		################ BLOCK 1 ################      
        pool_SE_1_32    = F.avg_pool2d(concat_5_16, kernel_size=(15, 15), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
        conv_SE_1_32_1  = self.conv_SE_1_32_1(pool_SE_1_32)
        relu_SE_1_32_1  = F.relu(conv_SE_1_32_1)
        conv_SE_1_32_2  = self.conv_SE_1_32_2(relu_SE_1_32_1)
        sigm_SE_1_32    = F.sigmoid(conv_SE_1_32_2)
        reshape_SE_1_32 = torch.reshape(input = sigm_SE_1_32, shape = (1,1024,1,1))
        scale_SE_1_32   = concat_5_16 * reshape_SE_1_32

		conv_1_32_1d_pad = F.pad(scale_SE_1_32, (1, 1, 1, 1))
        conv_1_32_1d    = self.conv_1_32_1d(conv_1_32_1d_pad)
        prelu_1_32_1d   = F.prelu(conv_1_32_1d, torch.from_numpy(_weights_dict['prelu_1/32_1d']['weights']))
        bn_1_32_1d      = self.bn_1_32_1d(prelu_1_32_1d)

        conv_1_32_2d_pad = F.pad(bn_1_32_1d, (1, 1, 1, 1))
        conv_1_32_2d    = self.conv_1_32_2d(conv_1_32_2d_pad)
        prelu_1_32_2d   = F.prelu(conv_1_32_2d, torch.from_numpy(_weights_dict['prelu_1/32_2d']['weights']))
        bn_1_32_2d      = self.bn_1_32_2d(prelu_1_32_2d)

        conv_1_32_3d    = self.conv_1_32_3d(bn_1_32_2d)
        prelu_1_32_3d   = F.prelu(conv_1_32_3d, torch.from_numpy(_weights_dict['prelu_1/32_3d']['weights']))
        bn_1_32_3d      = self.bn_1_32_3d(prelu_1_32_3d)

        deconv_1_16d	= self.deconv_1_16d(conv_1_32_3d)
        prelu_1_16d     = F.prelu(deconv_1_16d, torch.from_numpy(_weights_dict['prelu_1/16d']['weights']))
        bn_1_16d        = self.bn_1_16d(prelu_1_16d)

        pool_SE_1_16    = F.avg_pool2d(concat_4_24, kernel_size=(30, 30), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
        conv_SE_1_16_1  = self.conv_SE_1_16_1(pool_SE_1_16)
        relu_SE_1_16_1  = F.relu(conv_SE_1_16_1)
        conv_SE_1_16_2  = self.conv_SE_1_16_2(relu_SE_1_16_1)
        sigm_SE_1_16    = F.sigmoid(conv_SE_1_16_2)
        reshape_SE_1_16 = torch.reshape(input = sigm_SE_1_16, shape = (1,1024,1,1))
        scale_SE_1_16   = concat_4_24 * reshape_SE_1_16
		conv_SE_1_16    = self.conv_SE_1_16(scale_SE_1_16)
		bn_SE_1_16      = self.bn_SE_1_16(prelu_SE_1_16)
		#########################################

        ################ BLOCK 2 ################
		concat_1_16d    = torch.cat((bn_1_16d, bn_SE_1_16,), 1)

        conv_1_16_1d_pad = F.pad(concat_1_16d, (1, 1, 1, 1))
        conv_1_16_1d    = self.conv_1_16_1d(conv_1_16_1d_pad)
        prelu_1_16_1d   = F.prelu(conv_1_16_1d, torch.from_numpy(_weights_dict['prelu_1/16_1d']['weights']))
        bn_1_16_1d      = self.bn_1_16_1d(prelu_1_16_1d)

        conv_1_16_2d_pad = F.pad(bn_1_16_1d, (1, 1, 1, 1))
        conv_1_16_2d    = self.conv_1_16_2d(conv_1_16_2d_pad)
        prelu_1_16_2d   = F.prelu(conv_1_16_2d, torch.from_numpy(_weights_dict['prelu_1/16_2d']['weights']))
        bn_1_16_2d      = self.bn_1_16_2d(prelu_1_16_2d)

        conv_1_16_3d    = self.conv_1_16_3d(bn_1_16_2d)
        prelu_1_16_3d   = F.prelu(conv_1_16_3d, torch.from_numpy(_weights_dict['prelu_1/16_3d']['weights']))
        bn_1_16_3d      = self.bn_1_16_3d(prelu_1_16_3d)

        deconv_1_8d		= self.deconv_1_8d(conv_1_16_3d)
        prelu_1_8d      = F.prelu(deconv_1_8d, torch.from_numpy(_weights_dict['prelu_1/8d']['weights']))
        bn_1_8d         = self.bn_1_8d(prelu_1_8d)

        pool_SE_1_8     = F.avg_pool2d(concat_3_12, kernel_size=(60, 60), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
		conv_SE_1_8_1   = self.conv_SE_1_8_1(pool_SE_1_8)        
		relu_SE_1_8_1   = F.relu(conv_SE_1_8_1)
		conv_SE_1_8_2   = self.conv_SE_1_8_2(relu_SE_1_8_1)
		sigm_SE_1_8     = F.sigmoid(conv_SE_1_8_2)
		reshape_SE_1_8  = torch.reshape(input = sigm_SE_1_8, shape = (1,512,1,1))
		scale_SE_1_8    = concat_3_12 * reshape_SE_1_8
		conv_SE_1_8     = self.conv_SE_1_8(scale_SE_1_8)
		prelu_SE_1_8    = F.prelu(conv_SE_1_8, torch.from_numpy(_weights_dict['prelu_SE_1/8']['weights']))
		bn_SE_1_8       = self.bn_SE_1_8(prelu_SE_1_8)
		#########################################

        ################ BLOCK 3 ################																
		concat_1_8d     = torch.cat((bn_1_8d, bn_SE_1_8,), 1)

        conv_1_8_1d_pad = F.pad(concat_1_8d, (1, 1, 1, 1))
        conv_1_8_1d     = self.conv_1_8_1d(conv_1_8_1d_pad)
        prelu_1_8_1d    = F.prelu(conv_1_8_1d, torch.from_numpy(_weights_dict['prelu_1/8_1d']['weights']))
        bn_1_8_1d       = self.bn_1_8_1d(prelu_1_8_1d)

        conv_1_8_2d_pad = F.pad(bn_1_8_1d, (1, 1, 1, 1))
        conv_1_8_2d     = self.conv_1_8_2d(conv_1_8_2d_pad)
        prelu_1_8_2d    = F.prelu(conv_1_8_2d, torch.from_numpy(_weights_dict['prelu_1/8_2d']['weights']))
        bn_1_8_2d       = self.bn_1_8_2d(prelu_1_8_2d)

        conv_1_8_3d     = self.conv_1_8_3d(bn_1_8_2d)
        prelu_1_8_3d    = F.prelu(conv_1_8_3d, torch.from_numpy(_weights_dict['prelu_1/8_3d']['weights']))
        bn_1_8_3d       = self.bn_1_8_3d(prelu_1_8_3d)

        deconv_1_4d		= self.deconv_1_4d(conv_1_8_3d)
        prelu_1_4d      = F.prelu(deconv_1_4d, torch.from_numpy(_weights_dict['prelu_1/4d']['weights']))
        bn_1_4d         = self.bn_1_4d(prelu_1_4d)

        pool_SE_1_4     = F.avg_pool2d(concat_2_6, kernel_size=(120, 120), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
		conv_SE_1_4_1   = self.conv_SE_1_4_1(pool_SE_1_4)
		relu_SE_1_4_1   = F.relu(conv_SE_1_4_1)
		conv_SE_1_4_2   = self.conv_SE_1_4_2(relu_SE_1_4_1)
		sigm_SE_1_4     = F.sigmoid(conv_SE_1_4_2)
		reshape_SE_1_4  = torch.reshape(input = sigm_SE_1_4, shape = (1,256,1,1))
		scale_SE_1_4    = concat_2_6 * reshape_SE_1_4
		conv_SE_1_4     = self.conv_SE_1_4(scale_SE_1_4)
		prelu_SE_1_4    = F.prelu(conv_SE_1_4, torch.from_numpy(_weights_dict['prelu_SE_1/4']['weights']))
		bn_SE_1_4       = self.bn_SE_1_4(prelu_SE_1_4)
		#########################################

        ################ BLOCK 4 ################														        
		concat_1_4d     = torch.cat((bn_1_4d, bn_SE_1_4,), 1)

        conv_1_4_1d_pad = F.pad(concat_1_4d, (1, 1, 1, 1))
        conv_1_4_1d     = self.conv_1_4_1d(conv_1_4_1d_pad)
        prelu_1_4_1d    = F.prelu(conv_1_4_1d, torch.from_numpy(_weights_dict['prelu_1/4_1d']['weights']))
        bn_1_4_1d       = self.bn_1_4_1d(prelu_1_4_1d)

        conv_1_4_2d_pad = F.pad(bn_1_4_1d, (1, 1, 1, 1))
        conv_1_4_2d     = self.conv_1_4_2d(conv_1_4_2d_pad)
        prelu_1_4_2d    = F.prelu(conv_1_4_2d, torch.from_numpy(_weights_dict['prelu_1/4_2d']['weights']))
        bn_1_4_2d       = self.bn_1_4_2d(prelu_1_4_2d)

        conv_1_4_3d     = self.conv_1_4_3d(bn_1_4_2d)
        prelu_1_4_3d    = F.prelu(conv_1_4_3d, torch.from_numpy(_weights_dict['prelu_1/4_3d']['weights']))
        bn_1_4_3d       = self.bn_1_4_3d(prelu_1_4_3d)
        #########################################

        ################ PREDICTION AT 1/4 ################
        pred_1_4        = self.pred_1_4(bn_1_4_3d)

        ################ UNSAMPLE THE PREDICTION FROM 1/4 TO 1/1 ################
        pred_step_1 	= self.pred_step_1(pred_1_4)
        sigp_step_1     = F.sigmoid(pred_step_1)


        ################ SECONDARY NETWORK (FINE DECODER) STARTS HERE ################
        concat_step_1   = torch.cat((concat_input, sigp_step_1,), 1)

        ################ ATROUS POOLING BLOCK 1 ################
        conv_atrous1_1_pad = F.pad(concat_step_1, (1, 1, 1, 1))
        conv_atrous1_1  = self.conv_atrous1_1(conv_atrous1_1_pad)
        prelu_atrous1_1 = F.prelu(conv_atrous1_1, torch.from_numpy(_weights_dict['prelu_atrous1_1']['weights']))
        bn_atrous1_1    = self.bn_atrous1_1(prelu_atrous1_1)

        conv_atrous1_2_pad = F.pad(bn_atrous1_1, (1, 1, 1, 1))
        conv_atrous1_2  = self.conv_atrous1_2(conv_atrous1_2_pad)
        prelu_atrous1_2 = F.prelu(conv_atrous1_2, torch.from_numpy(_weights_dict['prelu_atrous1_2']['weights']))
        bn_atrous1_2    = self.bn_atrous1_2(prelu_atrous1_2)

        conv_atrous1_3  = self.conv_atrous1_3(bn_atrous1_2)
        prelu_atrous1_3 = F.prelu(conv_atrous1_3, torch.from_numpy(_weights_dict['prelu_atrous1_3']['weights']))
        bn_atrous1_3    = self.bn_atrous1_3(prelu_atrous1_3)
        ########################################################

        ################ ATROUS POOLING BLOCK 2 ################
        conv_atrous2_1_pad = F.pad(concat_step_1, (2, 2, 2, 2))
        conv_atrous2_1  = self.conv_atrous2_1(conv_atrous2_1_pad)
        prelu_atrous2_1 = F.prelu(conv_atrous2_1, torch.from_numpy(_weights_dict['prelu_atrous2_1']['weights']))
        bn_atrous2_1    = self.bn_atrous2_1(prelu_atrous2_1)

        conv_atrous2_2_pad = F.pad(bn_atrous2_1, (1, 1, 1, 1))
        conv_atrous2_2  = self.conv_atrous2_2(conv_atrous2_2_pad)
        prelu_atrous2_2 = F.prelu(conv_atrous2_2, torch.from_numpy(_weights_dict['prelu_atrous2_2']['weights']))
        bn_atrous2_2    = self.bn_atrous2_2(prelu_atrous2_2)

        conv_atrous2_3  = self.conv_atrous2_3(bn_atrous2_2)
        prelu_atrous2_3 = F.prelu(conv_atrous2_3, torch.from_numpy(_weights_dict['prelu_atrous2_3']['weights']))
        bn_atrous2_3    = self.bn_atrous2_3(prelu_atrous2_3)
        ########################################################

        ################ ATROUS POOLING BLOCK 3 ################
        conv_atrous3_1_pad = F.pad(concat_step_1, (3, 3, 3, 3))
        conv_atrous3_1  = self.conv_atrous3_1(conv_atrous3_1_pad)
        prelu_atrous3_1 = F.prelu(conv_atrous3_1, torch.from_numpy(_weights_dict['prelu_atrous3_1']['weights']))
        bn_atrous3_1    = self.bn_atrous3_1(prelu_atrous3_1)

        
        conv_atrous3_2_pad = F.pad(bn_atrous3_1, (1, 1, 1, 1))
        conv_atrous3_2  = self.conv_atrous3_2(conv_atrous3_2_pad)
       	prelu_atrous3_2 = F.prelu(conv_atrous3_2, torch.from_numpy(_weights_dict['prelu_atrous3_2']['weights']))
        bn_atrous3_2    = self.bn_atrous3_2(prelu_atrous3_2)
        
        
        conv_atrous3_3  = self.conv_atrous3_3(bn_atrous3_2)
        prelu_atrous3_3 = F.prelu(conv_atrous3_3, torch.from_numpy(_weights_dict['prelu_atrous3_3']['weights']))
        bn_atrous3_3    = self.bn_atrous3_3(prelu_atrous3_3)
        ########################################################

        ################ CONCAT + SQUEEZ & EXCITATION ################
        concat_step_2   = torch.cat((bn_atrous1_3, bn_atrous2_3, bn_atrous3_3,), 1)
        gpool_s2        = F.avg_pool2d(concat_step_2, kernel_size=(480, 480), stride=(1, 1), padding=(0,), ceil_mode=False, count_include_pad=False)
        conv_s2_down    = self.conv_s2_down(gpool_s2)
        relu_s2_down    = F.relu(conv_s2_down)
        conv_s2_up      = self.conv_s2_up(relu_s2_down)
        sig_s2_up       = F.sigmoid(conv_s2_up)
        resh_s2         = torch.reshape(input = sig_s2_up, shape = (1,48,1,1))
        scale_s2        = concat_step_2 * resh_s2
        ##############################################################

        ################ PREDICTION ################
        conv_p1_1_pad   = F.pad(scale_s2, (1, 1, 1, 1))
        conv_p1_1       = self.conv_p1_1(conv_p1_1_pad)
        prelu_p1_1      = F.prelu(conv_p1_1, torch.from_numpy(_weights_dict['prelu_p1_1']['weights']))
        bn_p1_1         = self.bn_p1_1(prelu_p1_1)
        pred_step_2     = self.pred_step_2(bn_p1_1)
        ############################################

        ################ PREDICTION ################
        sig_pred        = F.sigmoid(pred_step_2)
        ############################################
        return sig_pred

        ################ SECONDARY NETWORK (FINE DECORDER) ENDS HERE ################


    @staticmethod
    def __batch_normalization(dim, name, **kwargs):
        if   dim == 0 or dim == 1:  layer = nn.BatchNorm1d(**kwargs)
        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)
        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)
        else:           raise NotImplementedError()

        if 'scale' in _weights_dict[name]:
            layer.state_dict()['weight'].copy_(torch.from_numpy(_weights_dict[name]['scale']))
        else:
            layer.weight.data.fill_(1)

        if 'bias' in _weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(_weights_dict[name]['bias']))
        else:
            layer.bias.data.fill_(0)

        layer.state_dict()['running_mean'].copy_(torch.from_numpy(_weights_dict[name]['mean']))
        layer.state_dict()['running_var'].copy_(torch.from_numpy(_weights_dict[name]['var']))
        return layer

    @staticmethod
    def __conv(dim, name, **kwargs):
        if   dim == 1:  layer = nn.Conv1d(**kwargs)
        elif dim == 2:  layer = nn.Conv2d(**kwargs)
        elif dim == 3:  layer = nn.Conv3d(**kwargs)
        else:           raise NotImplementedError()

        layer.state_dict()['weight'].copy_(torch.from_numpy(_weights_dict[name]['weights']))
        if 'bias' in _weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(_weights_dict[name]['bias']))
        return layer

